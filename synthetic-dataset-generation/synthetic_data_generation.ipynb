{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query_generation import SyntheticQueryGenerationPrompt, QueryTemplateList, QueryTemplateListExtractor, TemplateVariableListGeneratorAndExtractor\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from itertools import product\n",
    "from query_answering import QueryAnswerPrompt\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your keys here:\n",
    "# In this example, we leverage Mirascopes OpenAICall functionality from two different providers, OpenAI and Groq.\n",
    "# We start with using the \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<API-Key>\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're creating a synthetic dataset of user queries and responses to train an LLM. The topic will be about matplotlib data visualization.\n",
    "\n",
    "Instead of generating a ton of examples with an LLM directly (and running up a huge bill), we will use a neat trick + the power of structured outputs with Mirascope.\n",
    "\n",
    "We will create a set of templated questions, where each template contains multiple different template variables, or values that are interchangeable with each other. We'll then generate those potential values as well.\n",
    "\n",
    "For each question, there will be combinations of template variables to sub in to the queries, generating a very large dataset off of minimal initial tokens. \n",
    "\n",
    "We will start off with the templated query generation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library_focus = 'matplotlib'\n",
    "task_type = \"data visualization\"\n",
    "generation_strategy = \"Query Generation with Task Templates\"\n",
    "generation_strategy_description = \"Generate a set of task templates that outline the structure of data visualization queries. These templates need to have a diverse set of templated variables (Denoted like [XXXX]). Do not fill them in, and create more types of templated variables beyond the example(s) given. The more unique templated variables, the better\"\n",
    "examples = [\"Create a [chart_type] using matplotlib to visualize [data_description] from [data_source] with [customization_options].\", \"Plot multiple [chart_type] in a single figure using matplotlib to compare [data_description] across different [category]\"]\n",
    "\n",
    "prompt = SyntheticQueryGenerationPrompt(library_focus=library_focus, task_type=task_type, generation_strategy=generation_strategy, generation_strategy_description=generation_strategy_description, examples=examples, num_results=5)\n",
    "query_generation_response = prompt.call()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we should see a series of queries, with specific parts of them in brackets. These are our template variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_generation_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will turn this raw text into a list of queries, and extract the set of templated variables from them.\n",
    "We could theoretically do this all in one call, but our focus is on quality of those examples, so we will generate the list first, then extract the list of queries + variables in a separate call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = QueryTemplateListExtractor(unextracted_query_list=query_generation_response.content).extract()\n",
    "assert isinstance(query_list, QueryTemplateList)\n",
    "print(query_list.templated_variables)\n",
    "print(query_list.queries)\n",
    "\n",
    "template_query_filename = \"template_query.jsonl\"\n",
    "\n",
    "with open(template_query_filename, 'w') as file:\n",
    "    for template_query in query_list.queries:\n",
    "        data = {\"template_query\" : template_query}\n",
    "        file.write(json.dumps(data)+ '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the set of template variables it's time to generate the potential variables to fill them. \n",
    "\n",
    "Using Mirascope's Extraction functionality, we can send the model a variable, and force it's output to be serializable into a Pydantic model containing a list of potential variables for that given template variable.\n",
    "\n",
    "For more information on how we do this, checkout `TemplateVariableListGeneratorAndExtractor` within `query_generation.py`\n",
    "\n",
    "These calls do sometimes fail, so we track which ones fail and retry them once if they do. This is simple enough to work for our small set of template variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_dict = {}\n",
    "failed_list = []\n",
    "\n",
    "for template_var in query_list.templated_variables:\n",
    "    print(f\"querying a list for: {template_var}\")\n",
    "    try: \n",
    "        example_list_model = TemplateVariableListGeneratorAndExtractor(template_variable=template_var, library_focus=library_focus).extract()\n",
    "\n",
    "    except AttributeError :\n",
    "        print(\"Attribute Error, retrying later\")\n",
    "        failed_list.append(template_var)\n",
    "\n",
    "    else:\n",
    "        print(example_list_model.options)\n",
    "        examples_dict[template_var] = example_list_model.options\n",
    "\n",
    "print(examples_dict)\n",
    "\n",
    "for template_var in failed_list:\n",
    "    print(f\"re-querying a list for: {template_var}\")\n",
    "    example_list_model = TemplateVariableListGeneratorAndExtractor(template_variable=template_var, library_focus=library_focus).extract()\n",
    "    print(example_list_model.options)\n",
    "    examples_dict[template_var] = example_list_model.options\n",
    "\n",
    "print(examples_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all the template variable values to a file for later.\n",
    "template_variable_values_filename = \"template_variable_values.jsonl\"\n",
    "\n",
    "with open(template_variable_values_filename, 'w') as file:\n",
    "    for key in examples_dict:\n",
    "        file.write(json.dumps({key: examples_dict[key]}) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our queries are templated, we can create multiple versions of each one for every possible combination of variables. Even with just our original 5 queries, there are multiple templates in each, allowing our final set to get quite large (~30,000 samples).\n",
    "\n",
    "Because we can calculate these queries given the original templated queries and their candidate variables, we wont need to save this overall list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(example_dict, queries):\n",
    "    result = []\n",
    "    for query in queries:\n",
    "        # Find all templated variables in the query string\n",
    "        variables = re.findall(r'\\[([^\\]]+)\\]', query)\n",
    "        \n",
    "        # Get the corresponding values for each variable from the dictionary\n",
    "        value_lists = [example_dict[var.strip()] for var in variables]\n",
    "        \n",
    "        # Generate all possible combinations of the values\n",
    "        combinations = list(product(*value_lists))\n",
    "        \n",
    "        # Replace the templated variables with their corresponding values\n",
    "        for combination in combinations:\n",
    "            filled_query = query\n",
    "            for var, value in zip(variables, combination):\n",
    "                filled_query = filled_query.replace(f'[{var}]', value)\n",
    "            result.append(filled_query)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = generate_combinations(example_dict=examples_dict, queries=query_list.queries)\n",
    "print(len(combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cost reasons, we will use Groq's api to generate the responses. To follow along, paste your Groq API Key here:\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<Groq-Key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this dataset is so large now, generating the synthetic responses will be quite costly and time consuming. Additionally, there isn't a tremendous amount of variance between each one. So we can randomly sample a subset to generate responses.\n",
    "\n",
    "We are using Mixtral via the Groq API. It's speed for consecutive requests lets us keep our code clean and running fairly fast. Our set of 2000 queries took roughly and hour and a half to run all the way through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_samples = random.sample(combos, 2000)\n",
    "answers = []\n",
    "for sample_query in random_samples:\n",
    "    print(f\"Evaluating: {sample_query}\")\n",
    "    code_sample = QueryAnswerPrompt(library_focus=library_focus, query=sample_query).call()\n",
    "    answers.append(code_sample)\n",
    "\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After generating the responses, we will save them with their queries to a jsonl file for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_response_filename = \"queries_and_responses.jsonl\"\n",
    "\n",
    "with open(query_response_filename, 'w') as file:\n",
    "    for query, response in zip(random_samples,answers):\n",
    "        data = {'query' : query, 'response': response.content}\n",
    "        file.write(json.dumps(data)+ '\\n')\n",
    "    \n",
    "    file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirascope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
